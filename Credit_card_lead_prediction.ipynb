{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Credit Card Lead Prediction</h1>\n",
    "\n",
    "<h2>Problem Statement</h2>\n",
    "\n",
    "Happy Customer Bank is a mid-sized private bank that deals in all kinds of banking products, like Savings accounts, Current accounts, investment products, credit products, among other offerings.\n",
    "\n",
    "The bank also cross-sells products to its existing customers and to do so they use different kinds of communication like tele-calling, e-mails, recommendations on net banking, mobile banking, etc. \n",
    "\n",
    "In this case, the Happy Customer Bank wants to cross sell its credit cards to its existing customers. The bank has identified a set of customers that are eligible for taking these credit cards.\n",
    "\n",
    "Now, the bank is looking for your help in identifying customers that could show higher intent towards a recommended credit card, given:\n",
    "\n",
    "* Customer details (gender, age, region etc.)\n",
    "* Details of his/her relationship with the bank (Channel_Code, Vintage, Avg_Asset_Value etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T11:11:38.844062Z",
     "start_time": "2021-06-18T11:11:12.339089Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.stats import chi2_contingency, chi2\n",
    "\n",
    "\n",
    "# Model Building\n",
    "from sklearn.naive_bayes import GaussianNB                                 # Naive Bayes\n",
    "from sklearn.linear_model import LogisticRegression                        # Logistic Regression\n",
    "from sklearn.neighbors import KNeighborsClassifier                         # KNN\n",
    "from sklearn.tree import DecisionTreeClassifier                            # Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier    # Random Forest, AdaBoost\n",
    "from sklearn.svm import SVC                                                # Support Vector Machines (SVM)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all' \n",
    "\n",
    "import winsound\n",
    "duration=2000    # milliseconds\n",
    "freq=440         # Hz\n",
    "# winsound.Beep(freq,duration)         # Use this command wherever required for alarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "data = pd.read_csv('train_s3TEQDk.csv')\n",
    "\n",
    "# Check the dimension of data set\n",
    "data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:45:27.761068Z",
     "start_time": "2021-06-18T08:45:27.451646Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check datatype of each variable\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:45:28.970280Z",
     "start_time": "2021-06-18T08:45:28.748045Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summary of continuous variables\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:45:30.816272Z",
     "start_time": "2021-06-18T08:45:29.871305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Summary of categorical variables\n",
    "data.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The ID column has unique ID for all the customers, so this does not give any information for prediction of lead.\n",
    "Hence we delete this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:31:25.766023Z",
     "start_time": "2021-06-18T09:31:25.690976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Delete 'ID' column \n",
    "data.drop('ID',axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T06:04:47.299421Z",
     "start_time": "2021-06-18T06:04:47.123668Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values in data set\n",
    "data.isnull().sum()/data.shape[0] *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here, Credit_Product is the only variable with 11.9% missing values. Deleting these missing values would result in a lot of information being lost. So, these values need to be imputed. Being categorical variable, the obvious choice is imputation with modal value. But imputation with modal value changes the distribution of the data, so other method of imputation must be implemented. Here, the values will be imputed with KNN imputaion, for which all the variables must be numeric as KNN imputer uses distance function for imputation. Before imputation let's explore the dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exploring Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:52:42.204361Z",
     "start_time": "2021-06-18T07:52:42.110278Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Continuous features\n",
    "conti_features = data.select_dtypes(exclude=object).columns\n",
    "conti_features\n",
    "data[conti_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:52:45.437512Z",
     "start_time": "2021-06-18T07:52:43.600944Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18,5))\n",
    "fig.suptitle(\"Interaction between Continuous Features & Lead\", fontsize=30, fontweight=15)\n",
    "\n",
    "sns.boxplot(x=\"Is_Lead\", y=\"Age\", data=data, ax=axes[0]);\n",
    "sns.boxplot(x=\"Is_Lead\", y=\"Vintage\", data=data, ax=axes[1]);\n",
    "sns.boxplot(x=\"Is_Lead\", y=\"Avg_Account_Balance\", data=data, ax=axes[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above plot shows that all the variables are positively skewed with little or no ouliers as such except for the variable 'Avg_Account_Balance' which has many outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:54:56.024557Z",
     "start_time": "2021-06-18T07:53:50.350799Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distribution of continuous variables\n",
    "data[conti_features[:-1]].plot(kind='density', subplots=True, layout=(1,3), figsize=(15,5), sharex=False, sharey=False, \n",
    "                           title=\"Distribution of Age, Vintage & Avg_Account_Balance\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:56:45.191360Z",
     "start_time": "2021-06-18T07:56:15.783584Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot of continuous variables\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(data[conti_features[:-1]])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There seems to be some positive correlation between Age & Vintage. Let's verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:56:45.369390Z",
     "start_time": "2021-06-18T07:56:45.195953Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Correlations between continuous variables\n",
    "print(\"Correlation(Age,Vintage) :\",data['Age'].corr(data['Vintage']))\n",
    "print(\"Correlation(Vintage,Avg_Account_Balance) :\",data['Vintage'].corr(data['Avg_Account_Balance']))\n",
    "print(\"Correlation(Age,Avg_Account_Balance) :\",data['Age'].corr(data['Avg_Account_Balance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here, it is verified that 'Age' & 'Vintage' are positively correlated with corr=0.63, but the correlation is not too high that one of them can be deleted to avoid the problem of multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:56:50.710660Z",
     "start_time": "2021-06-18T07:56:45.374395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18,5))\n",
    "fig.suptitle(\"Violin plot for better visualiusation of Distribution of Continuous Features\", fontsize=20, fontweight=15)\n",
    "\n",
    "sns.violinplot(x=data.Age, ax=axes[0]);\n",
    "sns.violinplot(x=data.Vintage, ax=axes[1]);\n",
    "sns.violinplot(x=data.Avg_Account_Balance, ax=axes[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:04:11.192123Z",
     "start_time": "2021-06-18T08:04:06.150928Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18,5))\n",
    "fig.suptitle(\"Violin plot after log transformation of Continuous Features\", fontsize=20, fontweight=15)\n",
    "\n",
    "dis_age = np.log(data.Age)\n",
    "dis_vin = np.log(data.Vintage)\n",
    "dis_aab = np.log(data.Avg_Account_Balance)\n",
    "\n",
    "\n",
    "sns.violinplot(x=dis_age, ax=axes[0]);\n",
    "sns.violinplot(x=dis_vin, ax=axes[1]);\n",
    "sns.violinplot(x=dis_aab, ax=axes[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:06:21.437835Z",
     "start_time": "2021-06-18T08:06:20.757058Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18,5))\n",
    "fig.suptitle(\"Box-plot of Continuous Features\", fontsize=30, fontweight=15)\n",
    "\n",
    "sns.boxplot(x=dis_age, ax=axes[0]);\n",
    "sns.boxplot(x=dis_vin, ax=axes[1]);\n",
    "sns.boxplot(x=dis_aab, ax=axes[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:09:09.302909Z",
     "start_time": "2021-06-18T08:09:08.582957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18,5))\n",
    "fig.suptitle(\"Interaction between Continuous Features & Lead\", fontsize=30, fontweight=15)\n",
    "\n",
    "sns.boxplot(x=\"Age\", data=data, ax=axes[0]);\n",
    "sns.boxplot(x=\"Vintage\", data=data, ax=axes[1]);\n",
    "sns.boxplot(x=\"Avg_Account_Balance\", data=data, ax=axes[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exploring Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract all categorical features\n",
    "categ_features = data.select_dtypes(include=object).columns\n",
    "categ_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Number of Males & Females\n",
    "data.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Number of Active & Inactive customers\n",
    "data.Is_Active.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of customers with & without Credit Product\n",
    "data.Credit_Product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of unique Region_Code\n",
    "print(data.Region_Code.unique())\n",
    "print(data.Region_Code.value_counts().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Occupation of customers & their number\n",
    "data.Occupation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Unique Channel code & their counts\n",
    "data.Channel_Code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18,10))\n",
    "fig.suptitle(\"Interaction between Categorical Features & Lead\", fontsize=30, fontweight=15)\n",
    "\n",
    "sns.countplot(data.Gender,hue=data.Is_Lead, ax=axes[0,0], palette='ocean');\n",
    "sns.countplot(data.Is_Active,hue=data.Is_Lead, ax=axes[0,1], palette='spring');\n",
    "sns.countplot(data.Credit_Product,hue=data.Is_Lead, ax=axes[0,2], palette='summer');\n",
    "sns.countplot(data.Region_Code,hue=data.Is_Lead, ax=axes[1,0], palette='autumn');\n",
    "sns.countplot(data.Occupation,hue=data.Is_Lead, ax=axes[1,1], palette='twilight');\n",
    "sns.countplot(data.Channel_Code,hue=data.Is_Lead, ax=axes[1,2], palette='rocket');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Encoding Categorical Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Testing significance of 'Region Code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Significance of Region_Code**\n",
    "\n",
    "The variable 'Region_Code' has 35 unique categories, so encoding them as dummy variables would create 34 new variables which increases the dimension and might also hamper the model performance due to sparse data. Frequency encoding is a better solution to go ahead with. Before encoding it would be wise to see if this variable is significant in prediction of 'Is_Lead'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Chi-Square test for significance of Region_Code in predicting Lead\n",
    "observed_values = pd.crosstab(data.Region_Code,data.Is_Lead)\n",
    "statistic, pvalue, dof, expected = chi2_contingency(observed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"p-value : {} \\nChi-Square statistic : {} \\nDegree of Freedom : {}\".format(pvalue,statistic,dof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Interpretation of test-statistic\n",
    "prob=0.95  # (1-alpha)% \n",
    "critical = chi2.ppf(prob, dof)\n",
    "print(\"Chi-Square statistic : {} and critical value : {}.\".format(statistic,critical))\n",
    "if abs(statistic) >= critical:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **If Statistic >= Critical Value:** significant result, reject null hypothesis (H0), dependent.\n",
    "\n",
    "- **If Statistic < Critical Value:** not significant result, fail to reject null hypothesis (H0), independent.\n",
    "\n",
    "Here, test statistic is greater then critical value. Therefore, the null-hypothesis is rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Interpretation of p-value\n",
    "alpha = 0.05\n",
    "print(\"P-value : {} and alpha : {}.\".format(pvalue,alpha))\n",
    "if pvalue <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **If p-value <= alpha:** significant result, reject null hypothesis (H0), dependent.\n",
    "\n",
    "- **If p-value > alpha:** not significant result, fail to reject null hypothesis (H0), independent.\n",
    "\n",
    "Here, as p-value is less than alpha=0.05. Therefore, the null-hypothesis H0 of Independence is rejected at 5% level of significance. \n",
    "\n",
    "**Region_Code is a significant feature in predicting Leads**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Encoding Categorical Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:31:31.995012Z",
     "start_time": "2021-06-18T09:31:31.919961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create copies of Data\n",
    "\n",
    "data1 = data.copy()\n",
    "data2 = data.copy()\n",
    "data3 = data.copy()\n",
    "\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:31:34.272272Z",
     "start_time": "2021-06-18T09:31:34.264269Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function for encodings\n",
    "\n",
    "def encode(data):\n",
    "    dict_Region = data.Region_Code.value_counts().to_dict()\n",
    "    data['Region_Code'] = data.Region_Code.map(dict_Region)\n",
    "    \n",
    "    data['Credit_Product'] = LabelEncoder().fit_transform(data.Credit_Product)\n",
    "    #data['Credit_Product'] = data.Credit_Product.map({'Yes': 1, 'No': 0},na_action=None)\n",
    "    data['Gender'] = data.Gender.map({'Male': 1, 'Female': 0})\n",
    "    data['Is_Active'] = data.Is_Active.map({'Yes' : 1, 'No' : 0})\n",
    "    data['Channel_Code'] = LabelEncoder().fit_transform(data.Channel_Code)\n",
    "    \n",
    "    dict_Occupation = data.Occupation.value_counts().to_dict()\n",
    "    data['Occupation'] = data.Occupation.map(dict_Occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:31:38.733651Z",
     "start_time": "2021-06-18T09:31:38.245366Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encode(data1)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:31:43.029608Z",
     "start_time": "2021-06-18T09:31:41.825000Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corr = data1.corr()\n",
    "sns.heatmap(corr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T06:03:49.068567Z",
     "start_time": "2021-06-18T06:03:48.758341Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fill missing values with 'mode'\n",
    "#data['Credit_Product'].fillna(data['Credit_Product'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T05:58:48.331688Z",
     "start_time": "2021-06-18T05:58:47.969353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split data into training & testing\n",
    "train, test = train_test_split(data1, test_size=0.2, random_state=19, stratify=data1['Is_Lead'])\n",
    "train.shape; test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train Valdation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T05:58:52.616606Z",
     "start_time": "2021-06-18T05:58:52.584595Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T06:02:49.598711Z",
     "start_time": "2021-06-18T06:02:49.558699Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate Features & Target\n",
    "y = train['Is_Lead']\n",
    "X = train.drop('Is_Lead',axis=1)\n",
    "X.shape; y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T06:02:50.533791Z",
     "start_time": "2021-06-18T06:02:50.421759Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split data into training & validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=19)\n",
    "X_train.shape; X_val.shape; y_train.shape; y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T06:02:52.920796Z",
     "start_time": "2021-06-18T06:02:52.904772Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Model instances\n",
    "\n",
    "lr = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "dtree = DecisionTreeClassifier(max_depth=5, random_state=101, max_features=None, min_samples_leaf=15)\n",
    "rfm = RandomForestClassifier(n_estimators=70, oob_score=True, n_jobs=-1,\n",
    "                             random_state=101, max_features=None, min_samples_leaf=15)\n",
    "ab = AdaBoostClassifier(n_estimators=50,learning_rate=1, random_state=14)          # base_estimator --> Decision tree (default)\n",
    "svc = SVC(kernel='linear', probability=True,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T06:02:54.692199Z",
     "start_time": "2021-06-18T06:02:54.572186Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fit model\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_hat = dtree.predict(X_val)\n",
    "\n",
    "# Classification\n",
    "cr = classification_report(y_true=y_val,y_pred=y_hat)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "acc = accuracy_score(y_true=y_val,y_pred=y_hat)\n",
    "pred_prob = dtree.predict_proba(X_val)\n",
    "auc_score = roc_auc_score(y_val, pred_prob[:,1])\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_true=y_val,y_pred=y_hat).ravel()\n",
    "sens = TP / (TP+FN)\n",
    "spec = TN / (TN+FP)\n",
    "prec = TP / (TP+FP)\n",
    "f1 = 2*prec*sens / (prec + sens)\n",
    "\n",
    "# Result\n",
    "result = pd.DataFrame({'Model': 'Decision Tree',\n",
    "                           'Accuracy Score':acc,\n",
    "                           'AUC Score': auc_score,\n",
    "                           'F1 Score': f1,\n",
    "                           'Precision': prec,\n",
    "                           'Sensitivity(Recall)': sens,\n",
    "                           'Specificity': spec }, index=[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T22:15:14.848Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "winsound.Beep(freq,duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat = svc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_val,y_pred=y_hat)\n",
    "pred_prob = svc.predict_proba(X_val)\n",
    "auc_score = roc_auc_score(y_val, pred_prob[:,1])\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_true=y_val,y_pred=y_hat).ravel()\n",
    "sens = TP / (TP+FN)\n",
    "spec = TN / (TN+FP)\n",
    "prec = TP / (TP+FP)\n",
    "f1 = 2*prec*sens / (prec + sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Model': 'Support Vector Classifier',\n",
    "                           'Accuracy Score':acc,\n",
    "                           'AUC Score': auc_score,\n",
    "                           'F1 Score': f1,\n",
    "                           'Precision': prec,\n",
    "                           'Sensitivity(Recall)': sens,\n",
    "                           'Specificity': spec }, index=[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_hat = nb.predict(X_val)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_true=y_val,y_pred=y_hat)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "acc = accuracy_score(y_true=y_val,y_pred=y_hat)\n",
    "pred_prob = nb.predict_proba(X_val)\n",
    "auc_score = roc_auc_score(y_val, pred_prob[:,1])\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_true=y_val,y_pred=y_hat).ravel()\n",
    "sens = TP / (TP+FN)\n",
    "spec = TN / (TN+FP)\n",
    "prec = TP / (TP+FP)\n",
    "f1 = 2*prec*sens / (prec + sens)\n",
    "\n",
    "# Result\n",
    "result = pd.DataFrame({'Model': 'Naive Bayes',\n",
    "                           'Accuracy Score':acc,\n",
    "                           'AUC Score': auc_score,\n",
    "                           'F1 Score': f1,\n",
    "                           'Precision': prec,\n",
    "                           'Sensitivity(Recall)': sens,\n",
    "                           'Specificity': spec }, index=[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T22:28:02.270688Z",
     "start_time": "2021-06-14T22:28:02.265686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "algos = [lr, nb, sgd, knn, dtree, rfm, ab]\n",
    "names =['Logistic Regression','Naive Bayes','SGD','KNN','Decision Tree','Random Forest', 'AdaBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T22:29:41.851019Z",
     "start_time": "2021-06-14T22:28:06.465210Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auc_list=[]\n",
    "acc_list=[]\n",
    "sensitivity=[]\n",
    "specificity=[]\n",
    "precision=[]\n",
    "f1_score=[]\n",
    "\n",
    "for name in algos:\n",
    "    \n",
    "    model = name\n",
    "    model.fit(X_train,y_train)\n",
    "    y_hat = model.predict(X_val)\n",
    "\n",
    "    pred_prob = model.predict_proba(X_val)\n",
    "\n",
    "    auc = roc_auc_score(y_true=y_val, y_score=pred_prob[:,1])\n",
    "    acc = accuracy_score(y_true=y_val,y_pred=y_hat)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_true=y_val,y_pred=y_hat).ravel()\n",
    "\n",
    "    sens = TP / (TP+FN)\n",
    "    spec = TN / (TN+FP)       \n",
    "    prec = TP / (TP+FP)\n",
    "    f1 = 2*prec*sens / (prec + sens)\n",
    "\n",
    "    auc_list.append(auc)          # AUC Score \n",
    "    acc_list.append(acc)          # Accuracy Score\n",
    "    sensitivity.append(sens)      # Sensitivity/Recall \n",
    "    specificity.append(spec)      # Specificity \n",
    "    precision.append(prec)        # Precision\n",
    "    f1_score.append(f1)           # F1 Score\n",
    "    winsound.Beep(freq,duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T22:31:21.615753Z",
     "start_time": "2021-06-14T22:31:21.608748Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'Model': names,\n",
    "                           'Accuracy Score':acc_list,\n",
    "                           'AUC Score': auc_list,\n",
    "                           'F1 Score': f1_score,\n",
    "                           'Precision': precision,\n",
    "                           'Sensitivity(Recall)': sensitivity,\n",
    "                           'Specificity': specificity })\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T22:31:24.768631Z",
     "start_time": "2021-06-14T22:31:24.743614Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T23:16:35.742570Z",
     "start_time": "2021-06-14T23:16:34.293811Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "X_reduced[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T23:17:51.885044Z",
     "start_time": "2021-06-14T23:17:51.869040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.round(pca.explained_variance_ratio_,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T23:17:14.141319Z",
     "start_time": "2021-06-14T23:17:14.109318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.round(1 - pca.explained_variance_ratio_.sum(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T23:18:47.376298Z",
     "start_time": "2021-06-14T23:18:47.360290Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_after_dim_reduce(X_reduced):\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            plt.scatter(X_reduced[i, 0], X_reduced[i, 1], c='b')\n",
    "        elif y[i] == 1:\n",
    "            plt.scatter(X_reduced[i, 0], X_reduced[i, 1], c='r')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T23:18:51.814135Z",
     "start_time": "2021-06-14T23:18:49.480410Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# IncrementalPCA\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 50\n",
    "inc_pca = IncrementalPCA(n_components=2)\n",
    "for X_batch in np.array_split(X, n_batches):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "\n",
    "X_reduced_inc_pca = inc_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced_inc_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# KernelPCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "rbf_pca = KernelPCA(n_components=2, kernel='rbf', gamma=0.03)\n",
    "X_reduced_kernel_rbf = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced_kernel_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "        (\"kpca\", KernelPCA(n_components=2)),\n",
    "        (\"log_reg\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\", \"poly\", \"linear\"]\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10);\n",
    "grid_search.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lin_pca = KernelPCA(n_components=2, kernel='linear', gamma=0.03)\n",
    "X_reduced_kernel_lin = lin_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced_kernel_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# LocallyLinearEmbedding\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, random_state=42)\n",
    "X_reduced_lle = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced_lle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MDS\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2, random_state=42)\n",
    "X_reduced_mds = mds.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced_mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Isomap\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "isomap = Isomap(n_components=2)\n",
    "X_reduced_isomap = isomap.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced_isomap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_after_dim_reduce(X_reduced_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_curve\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy : {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import scikitplot as skplt\n",
    "\n",
    "y_pred_proba = log_reg.predict_proba(X_test)\n",
    "skplt.metrics.plot_precision_recall(y_test, y_pred_proba)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with dimensinality reduction (Linear PCA)\n",
    "\n",
    "X_train_dr, X_test_dr, y_train_dr, y_test_dr = train_test_split(X_reduced_kernel_lin, y, test_size=0.2)\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_dr, y_train_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_dr = log_reg.predict(X_test_dr)\n",
    "acc_dr = accuracy_score(y_test_dr, y_pred_dr)\n",
    "print('Accuracy : {}'.format(acc_dr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_dr, y_pred_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with dimensinality reduction (MDS)\n",
    "\n",
    "X_train_mds, X_test_mds, y_train_mds, y_test_mds = train_test_split(X_reduced_mds, y, test_size=0.2)\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_mds, y_train_mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_mds = log_reg.predict(X_test_mds)\n",
    "acc_mds = accuracy_score(y_test_mds, y_pred_mds)\n",
    "print('Accuracy : {}'.format(acc_mds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_mds, y_pred_mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with dimensinality reduction (t-SNE)\n",
    "\n",
    "X_train_tsne, X_test_tsne, y_train_tsne, y_test_tsne = train_test_split(X_reduced_tsne, y, test_size=0.2)\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_tsne, y_train_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_tsne = log_reg.predict(X_test_tsne)\n",
    "acc_tsne = accuracy_score(y_test_tsne, y_pred_tsne)\n",
    "print('Accuracy : {}'.format(acc_tsne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_tsne, y_pred_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "\n",
    "from sklearn.cross_validation import KFold, RepeatedKFold, cross_val_score\n",
    "\n",
    "# Prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "repcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Create Model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Evaluate Model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(cross_val_score(model, X_train, y_train, cv=4))\n",
    "print(cross_val_score(model, X, y, cv=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Standardization & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_data)\n",
    "standardized_X = scaler.transform(X_data)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "\n",
    "# Normalization\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer().fit(X_data)\n",
    "normalized_X = scaler.transform(X_data)\n",
    "normalized_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imputing missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train KNN imputer on train set\n",
    "knn = KNNImputer(n_neighbors=10)\n",
    "knn.fit(train)\n",
    "\n",
    "impute_train= knn.transform(train)\n",
    "\n",
    "\n",
    "impute_train.shape; impute_train.dtypes\n",
    "\n",
    "# Impute test set by KNN imputer trained on train set\n",
    "impute_test= knn.transform(test)\n",
    "winsound.Beep(freq,duration)\n",
    "\n",
    "df_train = pd.DataFrame(impute_train, columns= data.columns)\n",
    "df_train.head()\n",
    "\n",
    "df_test = pd.DataFrame(impute_test, columns= data.columns)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(fpr2, tpr2, linestyle='--',color='green', label='KNN')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "320px",
    "width": "372px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
